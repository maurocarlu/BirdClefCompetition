{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25623250",
   "metadata": {},
   "source": [
    "# Progetto Machine Learning: Riconoscimento di Specie di Uccelli con CNN\n",
    "\n",
    "Questo notebook implementa un sistema di riconoscimento di specie di uccelli attraverso l'analisi di registrazioni audio della competizione BirdClef 2025. Il progetto utilizza un'architettura CNN per classificare gli audio convertiti in spettrogrammi Mel e include anche un sistema di configurazione automatica dell'ambiente per eseguire il codice su Kaggle, Google Colab o in locale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a61feb3",
   "metadata": {},
   "source": [
    "## 1. Importazione delle Librerie Necessarie\n",
    "\n",
    "Importiamo tutte le librerie necessarie per l'elaborazione audio, deep learning e visualizzazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fff52ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpprint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpp\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mipd\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn\\__init__.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpalettes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrelational\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregression\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcategorical\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn\\relational.py:20\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     VectorPlotter,\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     13\u001b[0m     adjust_legend_subtitles,\n\u001b[0;32m     14\u001b[0m     _default_color,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     _scatter_legend_artist,\n\u001b[0;32m     19\u001b[0m )\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_statistics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EstimateAggregator\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maxisgrid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FacetGrid, _facet_docs\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_docstrings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DocstringComponents, _core_docs\n",
      "File \u001b[1;32mc:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn\\_statistics.py:31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gaussian_kde\n\u001b[0;32m     32\u001b[0m     _no_scipy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\stats\\__init__.py:624\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m.. _statsrefmanual:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    619\u001b[0m \n\u001b[0;32m    620\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_warnings_errors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[0;32m    623\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[1;32m--> 624\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_py\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_variation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m variation\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\stats\\_stats_py.py:52\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Import unused here but needs to stay until end of deprecation periode\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# See https://github.com/scipy/scipy/issues/15765#issuecomment-1875564522\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m linalg  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m distributions\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _mstats_basic \u001b[38;5;28;01mas\u001b[39;00m mstats_basic\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_mstats_common\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _find_repeats, theilslopes, siegelslopes\n",
      "File \u001b[1;32mc:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\stats\\distributions.py:8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Author:  Travis Oliphant  2002-2011 with contributions from\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#          SciPy Developers 2004-2011\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#       instead of `git blame -Lxxx,+x`.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_distn_infrastructure\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (rv_discrete, rv_continuous, rv_frozen)  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _continuous_distns\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _discrete_distns\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:936\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1032\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1130\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Librerie di sistema e utilità\n",
    "import os\n",
    "import sys\n",
    "import platform\n",
    "import time\n",
    "import warnings\n",
    "import logging\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import pprint as pp\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import IPython.display as ipd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "# Librerie per data science e manipolazione dati\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Librerie per elaborazione audio\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Visualizzazione\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Ignoriamo i warning\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Configurazione del logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger('BirdClef')\n",
    "\n",
    "print(\"Librerie importate con successo!\")\n",
    "print(f\"PyTorch versione: {torch.__version__}\")\n",
    "print(f\"Python versione: {platform.python_version()}\")\n",
    "print(f\"Sistema operativo: {platform.system()} {platform.release()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99928a9a",
   "metadata": {},
   "source": [
    "## 2. Configurazione dell'Ambiente di Esecuzione\n",
    "\n",
    "In questa sezione configuriamo l'ambiente di esecuzione in modo che il notebook funzioni sia su Kaggle, che su Google Colab, che in locale. Il codice rileverà automaticamente l'ambiente e configurerà i percorsi di conseguenza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44310596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variabile per impostare manualmente l'ambiente\n",
    "# Modifica questa variabile in base all'ambiente in uso:\n",
    "# - 'kaggle' per l'ambiente Kaggle\n",
    "# - 'colab' per Google Colab\n",
    "# - 'local' per l'esecuzione in locale\n",
    "MANUAL_ENVIRONMENT = ''  # Impostare su 'kaggle', 'colab', o 'local' per forzare l'ambiente\n",
    "\n",
    "def detect_environment():\n",
    "    \"\"\"\n",
    "    Rileva se il notebook è in esecuzione su Kaggle, Google Colab o in locale.\n",
    "    Rispetta l'impostazione manuale se fornita.\n",
    "    \n",
    "    Returns:\n",
    "        str: 'kaggle', 'colab', o 'local'\n",
    "    \"\"\"\n",
    "    # Se l'ambiente è stato impostato manualmente, usa quello\n",
    "    if MANUAL_ENVIRONMENT in ['kaggle', 'colab', 'local']:\n",
    "        print(f\"Utilizzo ambiente impostato manualmente: {MANUAL_ENVIRONMENT}\")\n",
    "        return MANUAL_ENVIRONMENT\n",
    "    \n",
    "    # Verifica Kaggle con metodo più affidabile\n",
    "    # Verifica l'esistenza di directory specifiche di Kaggle\n",
    "    if os.path.exists('/kaggle/working') and os.path.exists('/kaggle/input'):\n",
    "        print(\"Rilevato ambiente Kaggle\")\n",
    "        return 'kaggle'\n",
    "    \n",
    "    # Verifica se è Google Colab\n",
    "    try:\n",
    "        import google.colab\n",
    "        return 'colab'\n",
    "    except ImportError:\n",
    "        pass\n",
    "    \n",
    "    # Se non è né Kaggle né Colab, allora è locale\n",
    "    return 'local'\n",
    "\n",
    "# Rileva l'ambiente attuale\n",
    "ENVIRONMENT = detect_environment()\n",
    "print(f\"Ambiente rilevato: {ENVIRONMENT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc69dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        # Rileva l'ambiente\n",
    "        self.environment = ENVIRONMENT  # Usa la variabile globale impostata in precedenza\n",
    "        \n",
    "        # Imposta i percorsi di base in base all'ambiente\n",
    "        if self.environment == 'kaggle':\n",
    "            self.COMPETITION_NAME = \"birdclef-2025\"\n",
    "            self.BASE_DIR = f\"/kaggle/input/{self.COMPETITION_NAME}\"\n",
    "            self.OUTPUT_DIR = \"/kaggle/working\"\n",
    "            self.MODELS_DIR = \"/kaggle/input\"  # Per i modelli pre-addestrati\n",
    "            \n",
    "            # Imposta subito i percorsi derivati per l'ambiente Kaggle\n",
    "            self._setup_derived_paths()\n",
    "            \n",
    "        elif self.environment == 'colab':\n",
    "            # In Colab, inizializza directory base temporanee\n",
    "            self.COMPETITION_NAME = \"birdclef-2025\"\n",
    "            self.OUTPUT_DIR = \"/content/output\"\n",
    "            self.MODELS_DIR = \"/content/models\"\n",
    "            \n",
    "            # Crea le directory di output\n",
    "            os.makedirs(self.OUTPUT_DIR, exist_ok=True)\n",
    "            os.makedirs(self.MODELS_DIR, exist_ok=True)\n",
    "            \n",
    "            # In Colab, BASE_DIR verrà impostato dopo il download\n",
    "            # quindi non impostiamo ancora i percorsi derivati\n",
    "            self.BASE_DIR = \"/content/placeholder\"  # Verrà sovrascritto dopo il download\n",
    "            \n",
    "            # Inizializza i percorsi dei file a None per ora\n",
    "            self.TRAIN_AUDIO_DIR = None\n",
    "            self.TEST_SOUNDSCAPES_DIR = None\n",
    "            self.TRAIN_CSV_PATH = None\n",
    "            self.TAXONOMY_CSV_PATH = None\n",
    "            self.SAMPLE_SUB_PATH = None\n",
    "            \n",
    "        else:  # locale\n",
    "            # In ambiente locale, i percorsi dipenderanno dalla tua configurazione\n",
    "            self.BASE_DIR = os.path.abspath(\".\")\n",
    "            self.OUTPUT_DIR = os.path.join(self.BASE_DIR, \"output\")\n",
    "            self.MODELS_DIR = os.path.join(self.BASE_DIR, \"models\")\n",
    "            \n",
    "            # Crea le directory se non esistono\n",
    "            os.makedirs(self.OUTPUT_DIR, exist_ok=True)\n",
    "            os.makedirs(self.MODELS_DIR, exist_ok=True)\n",
    "            \n",
    "            # Imposta i percorsi derivati\n",
    "            self._setup_derived_paths()\n",
    "        \n",
    "        # Parametri per il preprocessing audio\n",
    "        self.SR = 32000  # Sample rate\n",
    "        self.DURATION = 5  # Durata dei clip in secondi\n",
    "        self.N_MELS = 128  # Numero di bande Mel\n",
    "        self.N_FFT = 2048  # Dimensione finestra FFT\n",
    "        self.HOP_LENGTH = 512  # Hop length per STFT\n",
    "        self.FMIN = 0  # Frequenza minima per lo spettrogramma Mel\n",
    "        self.FMAX = self.SR / 2  # Frequenza massima\n",
    "        \n",
    "        # Parametri per il training\n",
    "        self.BATCH_SIZE = 32\n",
    "        self.EPOCHS = 5  # Mantieni basso per il modello baseline\n",
    "        self.LEARNING_RATE = 1e-3\n",
    "        self.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.NUM_WORKERS = 0  # Numero di worker per il DataLoader\n",
    "\n",
    "        # Parametri per inference/submission\n",
    "        self.TEST_CLIP_DURATION = 5  # Durata dei segmenti per la predizione (secondi)\n",
    "        self.N_CLASSES = 0  # Sarà impostato dopo aver caricato i dati\n",
    "\n",
    "    def _setup_derived_paths(self):\n",
    "        \"\"\"Imposta i percorsi derivati basati su BASE_DIR\"\"\"\n",
    "        # Utilizza la normale divisione di percorso di OS (non il backslash hardcoded)\n",
    "        self.TRAIN_AUDIO_DIR = os.path.join(self.BASE_DIR, \"train_audio\")\n",
    "        self.TEST_SOUNDSCAPES_DIR = os.path.join(self.BASE_DIR, \"test_soundscapes\")\n",
    "        self.TRAIN_CSV_PATH = os.path.join(self.BASE_DIR, \"train.csv\")\n",
    "        self.TAXONOMY_CSV_PATH = os.path.join(self.BASE_DIR, \"taxonomy.csv\") \n",
    "        self.SAMPLE_SUB_PATH = os.path.join(self.BASE_DIR, \"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283c196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "\n",
    "# Gestione download dati in Colab con kagglehub\n",
    "if config.environment == 'colab':\n",
    "    # Percorsi nella cache di kagglehub\n",
    "    cache_competition_path = \"/root/.cache/kagglehub/competitions/birdclef-2025\"\n",
    "    cache_model_path = \"/root/.cache/kagglehub/models/maurocarlu/simplecnn/PyTorch/default/1\"\n",
    "    cache_model_file = os.path.join(cache_model_path, \"baseline_bird_cnn_model_val.pth\")\n",
    "    \n",
    "    # Verifica se i dati sono già presenti nella cache\n",
    "    data_exists = os.path.exists(os.path.join(cache_competition_path, \"train.csv\"))\n",
    "    model_exists = os.path.exists(cache_model_file)\n",
    "    \n",
    "    if data_exists and model_exists:\n",
    "        print(\"I dati e il modello sono già presenti nella cache. Utilizzo copie esistenti.\")\n",
    "        birdclef_path = cache_competition_path\n",
    "        model_path = cache_model_path\n",
    "    else:\n",
    "        print(\"Scaricamento dati con kagglehub...\")\n",
    "        \n",
    "        try:\n",
    "            import kagglehub\n",
    "            \n",
    "            # Scarica solo i dati della competizione se necessario\n",
    "            if not data_exists:\n",
    "                print(\"Download dataset...\")\n",
    "                kagglehub.login()  # Mostra dialog di login interattivo\n",
    "                birdclef_path = kagglehub.competition_download('birdclef-2025')\n",
    "            else:\n",
    "                print(\"Dataset già presente nella cache.\")\n",
    "                birdclef_path = cache_competition_path\n",
    "                \n",
    "            # Scarica solo il modello se necessario\n",
    "            if not model_exists:\n",
    "                print(\"Download modello...\")\n",
    "                kagglehub.login()  # Potrebbe essere necessario riautenticarsi\n",
    "                model_path = kagglehub.model_download('maurocarlu/simplecnn/PyTorch/default/1')\n",
    "            else:\n",
    "                print(\"Modello già presente nella cache.\")\n",
    "                model_path = cache_model_path\n",
    "                \n",
    "            print(f\"Download completato.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Errore durante il download dei dati: {e}\")\n",
    "            print(\"Prova ad usare Google Drive o esegui su Kaggle.\")\n",
    "            \n",
    "            # Se il download fallisce ma i dati esistono parzialmente, usa quelli\n",
    "            if os.path.exists(cache_competition_path):\n",
    "                birdclef_path = cache_competition_path\n",
    "                print(f\"Usando i dati esistenti in: {birdclef_path}\")\n",
    "            if os.path.exists(cache_model_path):\n",
    "                model_path = cache_model_path\n",
    "                print(f\"Usando il modello esistente in: {model_path}\")\n",
    "    \n",
    "    # Aggiorna i percorsi nella configurazione\n",
    "    config.BASE_DIR = birdclef_path\n",
    "    config._setup_derived_paths()\n",
    "    config.MODELS_DIR = model_path\n",
    "    model_file = os.path.join(model_path, \"baseline_bird_cnn_model_val.pth\")\n",
    "    \n",
    "    print(f\"Dati disponibili in: {config.BASE_DIR}\")\n",
    "    print(f\"Modello disponibile in: {model_file}\")\n",
    "\n",
    "# Stampa percorsi aggiornati\n",
    "print(f\"\\nPercorso file CSV di training: {config.TRAIN_CSV_PATH}\")\n",
    "print(f\"Percorso directory audio di training: {config.TRAIN_AUDIO_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74f17ef",
   "metadata": {},
   "source": [
    "## 3. Configurazione del Modello e Parametri\n",
    "\n",
    "Definiamo i parametri di configurazione per il preprocessamento audio, la creazione dello spettrogramma Mel e l'addestramento della CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760b91ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I parametri principali sono già definiti nella classe Config\n",
    "# Verifichiamo l'esistenza delle directory e creiamo quelle necessarie per l'output\n",
    "\n",
    "def setup_output_directories():\n",
    "    \"\"\"\n",
    "    Configura le directory per l'output del progetto.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary con i percorsi delle directory di output\n",
    "    \"\"\"\n",
    "    # Directory principale di output\n",
    "    output_dir = config.OUTPUT_DIR\n",
    "    \n",
    "    # Sotto-directory per diversi tipi di output\n",
    "    dirs = {\n",
    "        'checkpoints': os.path.join(output_dir, 'checkpoints'),\n",
    "        'tensorboard': os.path.join(output_dir, 'tensorboard_logs'),\n",
    "        'predictions': os.path.join(output_dir, 'predictions'),\n",
    "        'submissions': os.path.join(output_dir, 'submissions'),\n",
    "        'visualizations': os.path.join(output_dir, 'visualizations'),\n",
    "    }\n",
    "    \n",
    "    # Crea tutte le directory\n",
    "    for dir_name, dir_path in dirs.items():\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        print(f\"Directory '{dir_name}' creata/verificata in: {dir_path}\")\n",
    "    \n",
    "    return dirs\n",
    "\n",
    "# Configura le directory di output\n",
    "output_dirs = setup_output_directories()\n",
    "\n",
    "# Crea un file di log per tenere traccia dei risultati\n",
    "log_file_path = os.path.join(config.OUTPUT_DIR, f\"experiment_log_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\")\n",
    "\n",
    "with open(log_file_path, 'w') as log_file:\n",
    "    log_file.write(f\"=== BirdClef Experiment Log ===\\n\")\n",
    "    log_file.write(f\"Date: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    log_file.write(f\"Environment: {config.environment}\\n\\n\")\n",
    "    log_file.write(\"Output directories:\\n\")\n",
    "    for dir_name, dir_path in output_dirs.items():\n",
    "        log_file.write(f\"- {dir_name}: {dir_path}\\n\")\n",
    "\n",
    "print(f\"File di log creato in: {log_file_path}\")\n",
    "\n",
    "# Memorizziamo i parametri di configurazione principali per l'addestramento\n",
    "print(\"\\nParametri di configurazione principali:\")\n",
    "print(f\"- Sample rate: {config.SR} Hz\")\n",
    "print(f\"- Durata clip audio: {config.DURATION} secondi\")\n",
    "print(f\"- Numero bande Mel: {config.N_MELS}\")\n",
    "print(f\"- Dimensione FFT: {config.N_FFT}\")\n",
    "print(f\"- Hop length: {config.HOP_LENGTH}\")\n",
    "print(f\"- Device: {config.DEVICE}\")\n",
    "print(f\"- Batch size: {config.BATCH_SIZE}\")\n",
    "print(f\"- Epoche: {config.EPOCHS}\")\n",
    "print(f\"- Learning rate: {config.LEARNING_RATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035b0570",
   "metadata": {},
   "source": [
    "## 4. Caricamento e Preprocessing dei Dati\n",
    "\n",
    "In questa sezione carichiamo i metadati dal file CSV di training, creiamo codifiche one-hot per le etichette delle specie e implementiamo funzioni per il caricamento e preprocessamento dei file audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340c54e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento dei metadati\n",
    "def load_metadata():\n",
    "    \"\"\"\n",
    "    Carica e prepara i metadati dal file CSV di training.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: training_df, all_species, labels_one_hot\n",
    "    \"\"\"\n",
    "    print(f\"Caricamento metadati da: {config.TRAIN_CSV_PATH}\")\n",
    "    train_df = pd.read_csv(config.TRAIN_CSV_PATH)\n",
    "    taxonomy_df = pd.read_csv(config.TAXONOMY_CSV_PATH)\n",
    "    sample_sub_df = pd.read_csv(config.SAMPLE_SUB_PATH)\n",
    "    \n",
    "    # Estrai tutte le etichette uniche\n",
    "    train_primary_labels = train_df['primary_label'].unique()\n",
    "    train_secondary_labels = set([lbl for sublist in train_df['secondary_labels'].apply(eval) \n",
    "                                 for lbl in sublist if lbl])\n",
    "    submission_species = sample_sub_df.columns[1:].tolist()  # Escludi row_id\n",
    "    \n",
    "    # Combina tutte le possibili etichette\n",
    "    all_species = sorted(list(set(train_primary_labels) | train_secondary_labels | set(submission_species)))\n",
    "    N_CLASSES = len(all_species)\n",
    "    config.N_CLASSES = N_CLASSES  # Aggiorna il numero di classi nella configurazione\n",
    "    \n",
    "    print(f\"Numero totale di specie trovate: {N_CLASSES}\")\n",
    "    print(f\"Prime 10 specie: {all_species[:10]}\")\n",
    "    \n",
    "    # Crea mappatura etichette-indici\n",
    "    species_to_int = {species: i for i, species in enumerate(all_species)}\n",
    "    int_to_species = {i: species for species, i in species_to_int.items()}\n",
    "    \n",
    "    # Aggiungi indici numerici al dataframe\n",
    "    train_df['primary_label_int'] = train_df['primary_label'].map(species_to_int)\n",
    "    \n",
    "    # Prepara target multi-etichetta\n",
    "    mlb = MultiLabelBinarizer(classes=all_species)\n",
    "    mlb.fit(None)  # Fit con tutte le classi\n",
    "    \n",
    "    def get_multilabel(row):\n",
    "        labels = eval(row['secondary_labels'])  # Valuta la lista di stringhe in modo sicuro\n",
    "        labels.append(row['primary_label'])\n",
    "        return list(set(labels))  # Assicura etichette uniche\n",
    "    \n",
    "    train_df['all_labels'] = train_df.apply(get_multilabel, axis=1)\n",
    "    train_labels_one_hot = mlb.transform(train_df['all_labels'])\n",
    "    \n",
    "    print(f\"Forma delle etichette one-hot: {train_labels_one_hot.shape}\")\n",
    "    \n",
    "    return train_df, all_species, train_labels_one_hot, species_to_int, int_to_species\n",
    "\n",
    "# Carica i metadati\n",
    "train_df, all_species, train_labels_one_hot, species_to_int, int_to_species = load_metadata()\n",
    "\n",
    "# Suddividi i dati in training e validation\n",
    "def split_data(train_df, labels_one_hot, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Suddivide il dataset in set di training e validation.\n",
    "    \n",
    "    Args:\n",
    "        train_df: DataFrame con i metadati\n",
    "        labels_one_hot: Array di etichette one-hot\n",
    "        test_size: Percentuale dei dati da usare per validation\n",
    "        random_state: Seed per riproducibilità\n",
    "        \n",
    "    Returns:\n",
    "        tuple: X_train_df, X_val_df, y_train_one_hot, y_val_one_hot\n",
    "    \"\"\"\n",
    "    # Indici per lo split\n",
    "    train_indices, val_indices = train_test_split(\n",
    "        range(len(train_df)),\n",
    "        test_size=test_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Crea i dataframe e gli array di etichette splittati\n",
    "    X_train_df = train_df.iloc[train_indices].reset_index(drop=True)\n",
    "    X_val_df = train_df.iloc[val_indices].reset_index(drop=True)\n",
    "    \n",
    "    y_train_one_hot = labels_one_hot[train_indices]\n",
    "    y_val_one_hot = labels_one_hot[val_indices]\n",
    "    \n",
    "    print(f\"Dimensioni Training Set: {X_train_df.shape}, Etichette: {y_train_one_hot.shape}\")\n",
    "    print(f\"Dimensioni Validation Set: {X_val_df.shape}, Etichette: {y_val_one_hot.shape}\")\n",
    "    \n",
    "    return X_train_df, X_val_df, y_train_one_hot, y_val_one_hot\n",
    "\n",
    "# Suddividi i dati in training e validation\n",
    "X_train_df, X_val_df, y_train_one_hot, y_val_one_hot = split_data(train_df, train_labels_one_hot)\n",
    "\n",
    "# Crea un test set solo se NON siamo su Kaggle\n",
    "if config.environment != 'kaggle':\n",
    "    # Crea un subset per il testing dai dati di validation\n",
    "    test_size = 0.1  # Percentuale di dati di validation da usare come test\n",
    "    test_indices, _ = train_test_split(range(len(X_val_df)), test_size=test_size, random_state=42)\n",
    "    X_test_df = X_val_df.iloc[test_indices].reset_index(drop=True)\n",
    "    y_test_one_hot = y_val_one_hot[test_indices]\n",
    "    print(f\"Dimensioni Test Set (creato da validation): {X_test_df.shape}, Etichette: {y_test_one_hot.shape}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Ambiente Kaggle rilevato: utilizzerò direttamente i dati di test dalla cartella test_soundscapes\")\n",
    "    \n",
    "    # Per Kaggle, dovremo creare un dataset speciale per le soundscapes di test\n",
    "    # Questo verrà utilizzato direttamente nella fase di generazione della submission\n",
    "    # Non creiamo X_test_df e test_dataset per ora\n",
    "    X_test_df = None\n",
    "    y_test_one_hot = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196eea4a",
   "metadata": {},
   "source": [
    "## 4.5 Analisi Esplorativa dei Dati (EDA)\n",
    "\n",
    "In questa sezione esploreremo le caratteristiche del dataset per comprendere meglio la distribuzione delle specie, le proprietà audio e identificare eventuali pattern nei dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519ccea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurazione stile visualizzazioni\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.set(style=\"whitegrid\", font_scale=1.1)\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "\n",
    "print(\"=== Statistiche di base del dataset ===\")\n",
    "print(f\"Numero totale di registrazioni: {len(train_df)}\")\n",
    "print(f\"Numero di specie uniche nel dataset: {len(all_species)}\")\n",
    "print(f\"Campi disponibili nei metadati: {train_df.columns.tolist()}\")\n",
    "\n",
    "# Verifichiamo i dati mancanti\n",
    "missing_data = train_df.isnull().sum()\n",
    "print(\"\\n=== Valori mancanti ===\")\n",
    "print(missing_data[missing_data > 0])\n",
    "\n",
    "# 1. Distribuzione delle specie nel dataset\n",
    "print(\"\\n=== Analisi delle Specie ===\")\n",
    "primary_species_count = train_df['primary_label'].value_counts()\n",
    "print(f\"Top 10 specie più frequenti:\")\n",
    "print(primary_species_count.head(10))\n",
    "\n",
    "print(f\"\\nSpecie meno frequenti (bottom 10):\")\n",
    "print(primary_species_count.tail(10))\n",
    "\n",
    "# Visualizzazione della distribuzione delle specie\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(x=primary_species_count.head(30).index, y=primary_species_count.head(30).values)\n",
    "plt.title('Top 30 Specie per Numero di Registrazioni')\n",
    "plt.xlabel('Specie')\n",
    "plt.ylabel('Numero di Registrazioni')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Analisi delle etichette secondarie\n",
    "secondary_labels_flat = [label for sublist in train_df['secondary_labels'].apply(eval) for label in sublist if label]\n",
    "secondary_species_count = Counter(secondary_labels_flat)\n",
    "\n",
    "print(\"\\n=== Analisi delle Etichette Secondarie ===\")\n",
    "print(f\"Numero di registrazioni con etichette secondarie: {len([x for x in train_df['secondary_labels'] if len(eval(x)) > 0])}\")\n",
    "print(f\"Numero medio di etichette secondarie per registrazione: {len(secondary_labels_flat) / len(train_df):.2f}\")\n",
    "\n",
    "if secondary_labels_flat:\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    top_secondary = dict(Counter(secondary_labels_flat).most_common(20))\n",
    "    sns.barplot(x=list(top_secondary.keys()), y=list(top_secondary.values()))\n",
    "    plt.title('Top 20 Etichette Secondarie')\n",
    "    plt.xlabel('Specie')\n",
    "    plt.ylabel('Conteggio come Etichetta Secondaria')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 3. Analisi di correlazione tra etichette primarie e secondarie\n",
    "correlation_df = pd.DataFrame(0, index=all_species, columns=['primary_count', 'secondary_count', 'total_count'])\n",
    "\n",
    "# Conteggio per etichette primarie\n",
    "for species in primary_species_count.index:\n",
    "    correlation_df.loc[species, 'primary_count'] = primary_species_count[species]\n",
    "\n",
    "# Conteggio per etichette secondarie\n",
    "for species, count in secondary_species_count.items():\n",
    "    if species in correlation_df.index:\n",
    "        correlation_df.loc[species, 'secondary_count'] = count\n",
    "\n",
    "# Calcolo totale\n",
    "correlation_df['total_count'] = correlation_df['primary_count'] + correlation_df['secondary_count']\n",
    "correlation_df['ratio_secondary_to_primary'] = correlation_df['secondary_count'] / correlation_df['primary_count'].replace(0, np.nan)\n",
    "\n",
    "print(\"\\n=== Relazione tra Etichette Primarie e Secondarie ===\")\n",
    "print(\"Top 10 specie che appaiono più frequentemente come secondarie rispetto a primarie:\")\n",
    "top_ratio = correlation_df.sort_values('ratio_secondary_to_primary', ascending=False).head(10)\n",
    "print(top_ratio[['primary_count', 'secondary_count', 'ratio_secondary_to_primary']])\n",
    "\n",
    "# 4. Analisi delle proprietà audio\n",
    "if os.path.exists(config.TRAIN_AUDIO_DIR):\n",
    "    print(\"\\n=== Analisi delle Proprietà Audio ===\")\n",
    "    \n",
    "    # Seleziona alcune specie diverse per l'analisi\n",
    "    sample_species = primary_species_count.head(5).index.tolist()\n",
    "    audio_properties = []\n",
    "    \n",
    "    for species in sample_species:\n",
    "        # Prendi fino a 3 file audio per specie\n",
    "        species_files = train_df[train_df['primary_label'] == species].head(3)['filename'].tolist()\n",
    "        \n",
    "        for filename in species_files:\n",
    "            file_path = os.path.join(config.TRAIN_AUDIO_DIR, filename)\n",
    "            if os.path.exists(file_path):\n",
    "                try:\n",
    "                    y, sr = librosa.load(file_path, sr=config.SR, duration=10)\n",
    "                    \n",
    "                    # Calcola proprietà audio\n",
    "                    duration = len(y) / sr\n",
    "                    mean_amplitude = np.mean(np.abs(y))\n",
    "                    rms = np.sqrt(np.mean(y**2))\n",
    "                    zero_crossings = sum(librosa.zero_crossings(y))\n",
    "                    spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)[0])\n",
    "                    \n",
    "                    audio_properties.append({\n",
    "                        'species': species,\n",
    "                        'filename': filename,\n",
    "                        'duration': duration,\n",
    "                        'mean_amplitude': mean_amplitude,\n",
    "                        'rms': rms,\n",
    "                        'zero_crossings': zero_crossings,\n",
    "                        'spectral_centroid': spectral_centroid\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"Errore nell'elaborazione di {filename}: {e}\")\n",
    "    \n",
    "    audio_df = pd.DataFrame(audio_properties)\n",
    "    if not audio_df.empty:\n",
    "        print(\"Statistiche delle proprietà audio per alcune specie:\")\n",
    "        # Usa numeric_only=True per escludere colonne non numeriche (come 'species' e 'filename')\n",
    "        print(audio_df.groupby('species').mean(numeric_only=True))\n",
    "        \n",
    "        # In alternativa, puoi selezionare esplicitamente solo le colonne numeriche\n",
    "        # numeric_cols = ['duration', 'mean_amplitude', 'rms', 'zero_crossings', 'spectral_centroid']\n",
    "        # print(audio_df.groupby('species')[numeric_cols].mean())\n",
    "        \n",
    "        # Visualizzazione delle proprietà audio\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        sns.violinplot(x='species', y='spectral_centroid', data=audio_df)\n",
    "        plt.title('Distribuzione del Centroide Spettrale per Specie')\n",
    "        plt.xlabel('Specie')\n",
    "        plt.ylabel('Centroide Spettrale')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Visualizza spettrogrammi di esempio per diverse specie\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        for i, (species, group) in enumerate(audio_df.groupby('species')):\n",
    "            if i >= 5:  # Limita a 5 specie\n",
    "                break\n",
    "                \n",
    "            file_path = os.path.join(config.TRAIN_AUDIO_DIR, group.iloc[0]['filename'])\n",
    "            if os.path.exists(file_path):\n",
    "                y, sr = librosa.load(file_path, sr=config.SR, duration=5)\n",
    "                plt.subplot(5, 1, i+1)\n",
    "                mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=config.N_MELS)\n",
    "                mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "                librosa.display.specshow(mel_spec_db, y_axis='mel', x_axis='time', sr=sr)\n",
    "                plt.title(f'Spettrogramma Mel per {species}')\n",
    "                plt.colorbar(format='%+2.0f dB')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# 5. Verifica sbilanciamento del dataset\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(primary_species_count, bins=30, kde=True)\n",
    "plt.title('Distribuzione del Numero di Registrazioni per Specie')\n",
    "plt.xlabel('Numero di Registrazioni')\n",
    "plt.ylabel('Conteggio Specie')\n",
    "plt.axvline(x=primary_species_count.median(), color='r', linestyle='--', \n",
    "            label=f'Mediana: {primary_species_count.median()}')\n",
    "plt.axvline(x=primary_species_count.mean(), color='g', linestyle='--', \n",
    "            label=f'Media: {primary_species_count.mean():.1f}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calcolo dell'indice di Gini per misurare lo sbilanciamento\n",
    "def gini_coefficient(x):\n",
    "    # Coefficiente di Gini: misura la disuguaglianza (0=perfetta uguaglianza, 1=massima disuguaglianza)\n",
    "    x = np.sort(x)\n",
    "    n = len(x)\n",
    "    index = np.arange(1, n+1)\n",
    "    return (np.sum((2*index - n - 1) * x)) / (n * np.sum(x))\n",
    "\n",
    "gini = gini_coefficient(primary_species_count.values)\n",
    "print(f\"\\nIndice di Gini per la distribuzione delle specie: {gini:.4f}\")\n",
    "print(f\"Questo indica {'un alto' if gini > 0.6 else 'un moderato' if gini > 0.3 else 'un basso'} livello di sbilanciamento nel dataset.\")\n",
    "\n",
    "print(\"\\nConsiderazioni finali dall'analisi esplorativa dei dati:\")\n",
    "print(\"1. Le specie sono distribuite in modo non uniforme, alcune hanno molte più registrazioni di altre.\")\n",
    "print(\"2. Ci sono specie che appaiono più frequentemente come etichette secondarie che primarie.\")\n",
    "print(f\"3. Lo sbilanciamento del dataset (indice di Gini: {gini:.4f}) potrebbe richiedere tecniche come oversampling/undersampling o pesi delle classi durante l'addestramento.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2281877",
   "metadata": {},
   "source": [
    "## Caricamento e pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3adbef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_audio(file_path, target_sr=config.SR, duration=config.DURATION):\n",
    "    \"\"\"\n",
    "    Carica un file audio, estrae i 5 secondi centrali e lo converte in spettrogramma Mel.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Percorso del file audio\n",
    "        target_sr: Sample rate target\n",
    "        duration: Durata target in secondi\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Spettrogramma Mel log-normalizzato\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Carica il file audio\n",
    "        y, sr = librosa.load(file_path, sr=target_sr, mono=True)\n",
    "        \n",
    "        # Estrai segmento centrale\n",
    "        target_len = int(target_sr * duration)\n",
    "        \n",
    "        if len(y) < target_len:\n",
    "            # Se il file audio è troppo corto, ripetilo fino a raggiungere la lunghezza necessaria\n",
    "            import math\n",
    "            n_copy = math.ceil(target_len / len(y))\n",
    "            if n_copy > 1:\n",
    "                y = np.tile(y, n_copy)  # Ripete l'array n_copy volte\n",
    "        \n",
    "        # Prendi il segmento centrale\n",
    "        start_idx = max(0, int(len(y) / 2 - target_len / 2))\n",
    "        end_idx = min(len(y), start_idx + target_len)\n",
    "        y = y[start_idx:end_idx]\n",
    "        \n",
    "        # Padda se ancora necessario\n",
    "        if len(y) < target_len:\n",
    "            y = np.pad(y, (0, target_len - len(y)), mode='constant')\n",
    "        \n",
    "        # Calcola lo spettrogramma Mel\n",
    "        mel_spec = librosa.feature.melspectrogram(\n",
    "            y=y, sr=sr,\n",
    "            n_fft=config.N_FFT,\n",
    "            hop_length=config.HOP_LENGTH,\n",
    "            n_mels=config.N_MELS,\n",
    "            fmin=config.FMIN,\n",
    "            fmax=config.FMAX\n",
    "        )\n",
    "        \n",
    "        # Converti in scala logaritmica (dB)\n",
    "        log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        \n",
    "        # Normalizza (opzionale, ma spesso utile)\n",
    "        min_val = np.min(log_mel_spec)\n",
    "        max_val = np.max(log_mel_spec)\n",
    "        if max_val > min_val:\n",
    "            log_mel_spec = (log_mel_spec - min_val) / (max_val - min_val)\n",
    "        else:\n",
    "            log_mel_spec = np.zeros_like(log_mel_spec)  # Gestisci clip silenziosi\n",
    "        \n",
    "        return log_mel_spec\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Errore nell'elaborazione di {file_path}: {e}\")\n",
    "        # Restituisci un array fittizio della forma attesa in caso di errore\n",
    "        time_steps = int(target_sr * duration / config.HOP_LENGTH) + 1\n",
    "        return np.zeros((config.N_MELS, time_steps), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31556e1",
   "metadata": {},
   "source": [
    "## 5. Dataset PyTorch per Dati Audio\n",
    "\n",
    "Creiamo un dataset PyTorch personalizzato per caricare e preparare i nostri dati audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301eb2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdDataset(Dataset):\n",
    "    def __init__(self, df, audio_dir, labels_one_hot, transform=None):\n",
    "        \"\"\"\n",
    "        Dataset per caricare e preparare i file audio di uccelli.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame con i metadati\n",
    "            audio_dir: Directory contenente i file audio\n",
    "            labels_one_hot: Array di etichette one-hot\n",
    "            transform: Trasformazioni da applicare (opzionale)\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.audio_dir = audio_dir\n",
    "        self.labels = labels_one_hot\n",
    "        self.transform = transform  # Per potenziali augmentation\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        # Costruzione del percorso del file\n",
    "        filename = row['filename']\n",
    "        file_path = os.path.join(self.audio_dir, filename)\n",
    "        \n",
    "        # Verifica se il file esiste prima di caricarlo\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"Attenzione: File non trovato in {file_path}. Verifica il percorso e la struttura dei dati.\")\n",
    "            # Restituisci dati fittizi o solleva un errore\n",
    "            time_steps = int(config.SR * config.DURATION / config.HOP_LENGTH) + 1\n",
    "            dummy_spec = torch.zeros((1, config.N_MELS, time_steps), dtype=torch.float32)\n",
    "            dummy_label = torch.zeros(config.N_CLASSES, dtype=torch.float32)\n",
    "            return dummy_spec, dummy_label\n",
    "            \n",
    "        # Carica e preprocessa l'audio -> Spettrogramma Mel\n",
    "        mel_spec = load_and_preprocess_audio(file_path)\n",
    "        \n",
    "        # Aggiungi dimensione del canale (necessaria per CNN) -> (1, n_mels, time_steps)\n",
    "        mel_spec = np.expand_dims(mel_spec, axis=0)\n",
    "        \n",
    "        # Converti in tensor\n",
    "        mel_spec_tensor = torch.tensor(mel_spec, dtype=torch.float32)\n",
    "        \n",
    "        # Ottieni le etichette corrispondenti\n",
    "        label_tensor = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        \n",
    "        # Applica trasformazioni se presenti\n",
    "        if self.transform:\n",
    "            mel_spec_tensor = self.transform(mel_spec_tensor)\n",
    "            \n",
    "        return mel_spec_tensor, label_tensor\n",
    "\n",
    "# Creiamo i dataset e i dataloader\n",
    "train_dataset = BirdDataset(X_train_df, config.TRAIN_AUDIO_DIR, y_train_one_hot)\n",
    "val_dataset = BirdDataset(X_val_df, config.TRAIN_AUDIO_DIR, y_val_one_hot)\n",
    "if config.environment != 'kaggle':\n",
    "    # Creiamo il test dataset come BirdDataset regolare\n",
    "    test_dataset = BirdDataset(X_test_df, config.TRAIN_AUDIO_DIR, y_test_one_hot)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=config.BATCH_SIZE, \n",
    "    shuffle=True,\n",
    "    num_workers=config.NUM_WORKERS, \n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=config.BATCH_SIZE, \n",
    "    shuffle=False,\n",
    "    num_workers=config.NUM_WORKERS, \n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "\n",
    "# Crea il test loader solo se non siamo su Kaggle\n",
    "if config.environment != 'kaggle':\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=config.BATCH_SIZE, \n",
    "        shuffle=False,\n",
    "        num_workers=config.NUM_WORKERS\n",
    "    )\n",
    "    \n",
    "    print(f\"Numero di sample nel training set: {len(train_dataset)}\")\n",
    "    print(f\"Numero di sample nel validation set: {len(val_dataset)}\")\n",
    "    print(f\"Numero di sample nel test set: {len(test_dataset)}\")\n",
    "    print(f\"Numero di batch di training per epoca: {len(train_loader)}\")\n",
    "    print(f\"Numero di batch di validation per epoca: {len(val_loader)}\")\n",
    "    print(f\"Numero di batch di test: {len(test_loader)}\")\n",
    "else:\n",
    "    # Su Kaggle non creiamo un test_loader standard\n",
    "    test_loader = None\n",
    "    \n",
    "    print(f\"Numero di sample nel training set: {len(train_dataset)}\")\n",
    "    print(f\"Numero di sample nel validation set: {len(val_dataset)}\")\n",
    "    print(f\"Numero di batch di training per epoca: {len(train_loader)}\")\n",
    "    print(f\"Numero di batch di validation per epoca: {len(val_loader)}\")\n",
    "    print(\"Test set: utilizzerò direttamente i file nella cartella test_soundscapes\")\n",
    "\n",
    "print(f\"Numero di sample nel training set: {len(train_dataset)}\")\n",
    "print(f\"Numero di sample nel validation set: {len(val_dataset)}\")\n",
    "print(f\"Numero di batch di training per epoca: {len(train_loader)}\")\n",
    "print(f\"Numero di batch di validation per epoca: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439e60da",
   "metadata": {},
   "source": [
    "## 6. Definizione del Modello CNN\n",
    "\n",
    "Implementiamo una semplice architettura CNN per la classificazione degli spettrogrammi Mel degli audio di uccelli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a661eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleBirdCNN(nn.Module):\n",
    "    def __init__(self, num_classes=config.N_CLASSES):\n",
    "        super(SimpleBirdCNN, self).__init__()\n",
    "        # Input shape: (batch_size, 1, n_mels, time_steps)\n",
    "        # Esempio time_steps per audio di 5s: int(32000 * 5 / 512) + 1 = 313\n",
    "        \n",
    "        # Primo blocco convoluzionale\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Secondo blocco convoluzionale\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Terzo blocco convoluzionale\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Utilizziamo AdaptiveMaxPool2d per garantire una dimensione di output fissa\n",
    "        # indipendentemente dalle dimensioni di input\n",
    "        self.adaptive_pool = nn.AdaptiveMaxPool2d((4, 4))  # Output fisso (4, 4)\n",
    "        flattened_size = 128 * 4 * 4  # 128 filtri × 4 × 4 output\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(flattened_size, 256)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)  # Aggiungiamo dropout per regolarizzazione\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        # Nessuna attivazione finale perché useremo BCEWithLogitsLoss\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Forward pass attraverso i layer convoluzionali\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = self.pool3(self.relu3(self.conv3(x)))\n",
    "        x = self.adaptive_pool(x)  # Garantisci dimensione fissa\n",
    "        \n",
    "        # Appiattisci e passa attraverso i layer fully connected\n",
    "        x = self.flatten(x) if hasattr(self, 'flatten') else x.view(x.size(0), -1)\n",
    "        x = self.dropout(self.relu4(self.fc1(x)))\n",
    "        x = self.fc2(x)  # Output raw logits\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Inizializza il modello\n",
    "model = SimpleBirdCNN(num_classes=config.N_CLASSES).to(config.DEVICE)\n",
    "\n",
    "# Definisci loss e optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()  # Adatto per classificazione multi-etichetta\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.LEARNING_RATE)\n",
    "\n",
    "print(f\"Modello caricato su {config.DEVICE}\")\n",
    "print(f\"Numero di classi: {config.N_CLASSES}\")\n",
    "print(f\"Riepilogo del modello:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84557c",
   "metadata": {},
   "source": [
    "## 7. Addestramento e Validazione del Modello\n",
    "\n",
    "Implementiamo il ciclo di addestramento con supporto per il caricamento di modelli pre-addestrati o l'addestramento da zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84f83ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, \n",
    "                epochs=config.EPOCHS, device=config.DEVICE, \n",
    "                model_save_path=None, model_load_path=None):\n",
    "    \"\"\"\n",
    "    Addestra il modello e valuta su validation set.\n",
    "    \n",
    "    Args:\n",
    "        model: Modello PyTorch da addestrare\n",
    "        train_loader: DataLoader per dati di training\n",
    "        val_loader: DataLoader per dati di validation\n",
    "        criterion: Funzione di loss\n",
    "        optimizer: Ottimizzatore\n",
    "        epochs: Numero di epoche di training\n",
    "        device: Device per l'addestramento ('cuda' o 'cpu')\n",
    "        model_save_path: Path dove salvare il modello addestrato\n",
    "        model_load_path: Path da cui caricare un modello pre-addestrato\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (train_losses, val_losses, total_training_time)\n",
    "    \"\"\"\n",
    "    # Flag che indica se serve fare training\n",
    "    needs_training = True\n",
    "    \n",
    "    # Controlla se il file modello esiste\n",
    "    if model_load_path and os.path.exists(model_load_path):\n",
    "        print(f\"Modello pre-addestrato trovato in {model_load_path}. Caricamento...\")\n",
    "        try:\n",
    "            model.load_state_dict(torch.load(model_load_path, map_location=device))\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            print(\"Modello caricato con successo.\")\n",
    "            train_losses = []\n",
    "            val_losses = []\n",
    "            total_training_time = 0\n",
    "            needs_training = False\n",
    "        except Exception as e:\n",
    "            print(f\"Errore durante il caricamento del modello: {e}. Si procederà con il training.\")\n",
    "            train_losses = []\n",
    "            val_losses = []\n",
    "    else:\n",
    "        print(\"Nessun modello pre-addestrato trovato. Si procederà con il training.\")\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "    \n",
    "    # Esegui training solo se necessario\n",
    "    if needs_training:\n",
    "        start_time_total = time.time()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            epoch_start_time = time.time()\n",
    "            \n",
    "            # --- Fase di Training ---\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            pbar_train = tqdm(enumerate(train_loader), total=len(train_loader), \n",
    "                             desc=f\"Epoca {epoch+1}/{epochs} [Train]\", leave=True)\n",
    "            \n",
    "            for i, (inputs, labels) in pbar_train:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                avg_loss = running_loss / (i + 1)\n",
    "                pbar_train.set_postfix({'loss': f\"{avg_loss:.4f}\"})\n",
    "            \n",
    "            epoch_train_loss = running_loss / len(train_loader)\n",
    "            train_losses.append(epoch_train_loss)\n",
    "            \n",
    "            # --- Fase di Validation ---\n",
    "            model.eval()\n",
    "            running_val_loss = 0.0\n",
    "            pbar_val = tqdm(enumerate(val_loader), total=len(val_loader), \n",
    "                           desc=f\"Epoca {epoch+1}/{epochs} [Val]\", leave=True)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for i, (val_inputs, val_labels) in pbar_val:\n",
    "                    val_inputs = val_inputs.to(device)\n",
    "                    val_labels = val_labels.to(device)\n",
    "                    \n",
    "                    val_outputs = model(val_inputs)\n",
    "                    val_loss = criterion(val_outputs, val_labels)\n",
    "                    running_val_loss += val_loss.item()\n",
    "                    avg_val_loss = running_val_loss / (i + 1)\n",
    "                    pbar_val.set_postfix({'val_loss': f\"{avg_val_loss:.4f}\"})\n",
    "            \n",
    "            epoch_val_loss = running_val_loss / len(val_loader)\n",
    "            val_losses.append(epoch_val_loss)\n",
    "            \n",
    "            epoch_end_time = time.time()\n",
    "            epoch_duration = epoch_end_time - epoch_start_time\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {epoch_train_loss:.4f}, \"\n",
    "                  f\"Val Loss: {epoch_val_loss:.4f}, Duration: {epoch_duration:.2f} sec\")\n",
    "        \n",
    "        end_time_total = time.time()\n",
    "        total_training_time = end_time_total - start_time_total\n",
    "        print(f\"\\nTraining terminato in {total_training_time/60:.2f} minuti\")\n",
    "        \n",
    "        # Salva il modello addestrato\n",
    "        if model_save_path:\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"Modello salvato in {model_save_path}\")\n",
    "    else:\n",
    "        print(\"Training saltato perché il modello è stato caricato.\")\n",
    "    \n",
    "    # Visualizza le curve di loss\n",
    "    if train_losses and val_losses:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "        plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
    "        plt.xlabel('Epoche')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Curve di Loss di Training e Validation')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    \n",
    "    return train_losses, val_losses, total_training_time\n",
    "\n",
    "# Percorsi per caricamento/salvataggio del modello\n",
    "if config.environment == 'kaggle':\n",
    "    # Correzione percorso di caricamento\n",
    "    model_load_path = \"/kaggle/input/simplecnn/pytorch/default/1/baseline_bird_cnn_model_val.pth\"\n",
    "    # Il percorso di salvataggio è corretto, ma per coerenza possiamo scriverlo così\n",
    "    model_save_path = os.path.join(config.OUTPUT_DIR, \"birdclef_trained_model.pth\")\n",
    "else:\n",
    "    # Per altri ambienti, usa i path locali\n",
    "    model_load_path = os.path.join(config.MODELS_DIR, \"baseline_bird_cnn_model_val.pth\") if os.path.exists(os.path.join(config.MODELS_DIR, \"baseline_bird_cnn_model_val.pth\")) else None\n",
    "    model_save_path = os.path.join(output_dirs['checkpoints'], f\"birdclef_model_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.pth\")\n",
    "\n",
    "# Addestra il modello\n",
    "train_losses, val_losses, training_time = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    epochs=config.EPOCHS,\n",
    "    device=config.DEVICE,\n",
    "    model_save_path=model_save_path,\n",
    "    model_load_path=model_load_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cdcb9f",
   "metadata": {},
   "source": [
    "## 8. Valutazione sul Dataset di Test\n",
    "\n",
    "Valutiamo le prestazioni del modello sul nostro dataset di test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2828831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion=None, device=config.DEVICE):\n",
    "    \"\"\"\n",
    "    Valuta il modello sul dataset di test.\n",
    "    \n",
    "    Args:\n",
    "        model: Modello PyTorch da valutare\n",
    "        test_loader: DataLoader per dati di test\n",
    "        criterion: Funzione di loss (opzionale)\n",
    "        device: Device per l'inferenza ('cuda' o 'cpu')\n",
    "        \n",
    "    Returns:\n",
    "        dict: Risultati della valutazione\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(test_loader, desc=\"Valutazione\"):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            if criterion:\n",
    "                loss = criterion(outputs, targets)\n",
    "                test_loss += loss.item()\n",
    "            \n",
    "            # Applica sigmoid per ottenere probabilità\n",
    "            probabilities = torch.sigmoid(outputs)\n",
    "            \n",
    "            # Raccogli previsioni e target\n",
    "            all_predictions.append(probabilities.cpu().numpy())\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "    \n",
    "    # Concatena batch\n",
    "    all_predictions = np.concatenate(all_predictions)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "    \n",
    "    # Calcola metriche\n",
    "    if criterion:\n",
    "        avg_loss = test_loss / len(test_loader)\n",
    "    else:\n",
    "        avg_loss = None\n",
    "    \n",
    "    # Calcola accuracy e altre metriche\n",
    "    predicted_labels = (all_predictions >= 0.5).astype(int)\n",
    "    accuracy = np.mean(predicted_labels == all_targets)\n",
    "    \n",
    "    # Si possono aggiungere altre metriche come precision, recall, F1, ecc.\n",
    "    \n",
    "    results = {\n",
    "        'loss': avg_loss,\n",
    "        'accuracy': accuracy,\n",
    "        'predictions': all_predictions,\n",
    "        'targets': all_targets\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Valuta il modello sul test set\n",
    "if test_loader is not None:\n",
    "    print(\"\\nValutazione sul test set creato dai dati di validazione:\")\n",
    "    test_results = evaluate_model(model, test_loader, criterion)\n",
    "    \n",
    "    print(f\"Loss: {test_results['loss']:.4f}\" if test_results['loss'] else \"Loss: N/A\")\n",
    "    print(f\"Accuracy: {test_results['accuracy']:.4f}\")\n",
    "    \n",
    "        # Visualizzazione delle curve ROC e altre metriche\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "    # Calcola media delle curve ROC per tutte le classi\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    roc_auc_scores = []\n",
    "\n",
    "    for i in range(config.N_CLASSES):\n",
    "        fpr, tpr, _ = roc_curve(test_results['targets'][:, i], test_results['predictions'][:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "        \n",
    "        # Visualizza solo alcune curve per evitare sovraffollamento\n",
    "        if i % 50 == 0:  # Mostra una curva ogni 50 classi\n",
    "            plt.plot(fpr, tpr, alpha=0.3, label=f'Classe {i} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "    # Calcola e visualizza la curva ROC media\n",
    "    plt.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "    mean_auc = np.mean(roc_auc_scores)\n",
    "    plt.title(f'Curve ROC per classificazione multi-etichetta (AUC medio = {mean_auc:.2f})')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"AUC medio su tutte le classi: {mean_auc:.4f}\")\n",
    "\n",
    "    # Top 10 classi con maggior AUC\n",
    "    top_classes = sorted([(i, auc_score) for i, auc_score in enumerate(roc_auc_scores)], \n",
    "                        key=lambda x: x[1], reverse=True)[:10]\n",
    "    print(\"\\nTop 10 classi per performance (AUC):\")\n",
    "    for idx, score in top_classes:\n",
    "        species_name = int_to_species.get(idx, f\"Classe {idx}\")\n",
    "        print(f\"{species_name}: {score:.4f}\")\n",
    "\n",
    "    # Bottom 10 classi con minor AUC\n",
    "    bottom_classes = sorted([(i, auc_score) for i, auc_score in enumerate(roc_auc_scores)], \n",
    "                        key=lambda x: x[1])[:10]\n",
    "    print(\"\\nBottom 10 classi per performance (AUC):\")\n",
    "    for idx, score in bottom_classes:\n",
    "        species_name = int_to_species.get(idx, f\"Classe {idx}\")\n",
    "        print(f\"{species_name}: {score:.4f}\")\n",
    "else:\n",
    "    print(\"\\nSalto la valutazione sul test set creato da validation perché siamo su Kaggle.\")\n",
    "    print(\"Il modello sarà valutato direttamente sulla submission generata dai file test_soundscapes.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d4f5c9",
   "metadata": {},
   "source": [
    "## 9. Generazione della Submission\n",
    "\n",
    "Elaborazione delle soundscape di test e generazione del file di submission nel formato richiesto dalla competizione BirdClef."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de56ff81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission_simple(model, device=config.DEVICE):\n",
    "    \"\"\"\n",
    "    Genera un file di submission usando una segmentazione semplificata.\n",
    "    \n",
    "    Args:\n",
    "        model: Modello PyTorch addestrato\n",
    "        device: Device per inferenza ('cuda' o 'cpu')\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame di submission\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Set seed per riproducibilità\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Percorso dei test soundscapes\n",
    "    test_soundscape_path = config.TEST_SOUNDSCAPES_DIR\n",
    "    test_soundscapes = [os.path.join(test_soundscape_path, afile) \n",
    "                        for afile in sorted(os.listdir(test_soundscape_path)) \n",
    "                        if afile.endswith('.ogg')]\n",
    "    \n",
    "    print(f\"Elaborazione di {len(test_soundscapes)} file soundscape...\")\n",
    "    \n",
    "    # Crea DataFrame per le predizioni\n",
    "    predictions = pd.DataFrame(columns=['row_id'] + all_species)\n",
    "    \n",
    "    for soundscape in tqdm(test_soundscapes, desc=\"Elaborazione soundscapes\"):\n",
    "        # Carica audio\n",
    "        sig, rate = librosa.load(path=soundscape, sr=config.SR)\n",
    "        \n",
    "        # Split in segmenti da 5 secondi\n",
    "        segment_length = rate * config.TEST_CLIP_DURATION\n",
    "        chunks = []\n",
    "        for i in range(0, len(sig), segment_length):\n",
    "            chunk = sig[i:i+segment_length]\n",
    "            # Padda se necessario\n",
    "            if len(chunk) < segment_length:\n",
    "                chunk = np.pad(chunk, (0, segment_length - len(chunk)), mode='constant')\n",
    "            chunks.append(chunk)\n",
    "        \n",
    "        # Genera predizioni per ogni segmento\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            # Calcola row_id (nome file + tempo finale del segmento in secondi)\n",
    "            file_name = os.path.basename(soundscape).split('.')[0]\n",
    "            row_id = f\"{file_name}_{i * config.TEST_CLIP_DURATION + config.TEST_CLIP_DURATION}\"\n",
    "            \n",
    "            # Calcola spettrogramma Mel\n",
    "            mel_spec = librosa.feature.melspectrogram(\n",
    "                y=chunk, sr=config.SR,\n",
    "                n_fft=config.N_FFT,\n",
    "                hop_length=config.HOP_LENGTH,\n",
    "                n_mels=config.N_MELS,\n",
    "                fmin=config.FMIN,\n",
    "                fmax=config.FMAX\n",
    "            )\n",
    "            \n",
    "            # Converti in scala logaritmica (dB) e normalizza\n",
    "            log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "            min_val = np.min(log_mel_spec)\n",
    "            max_val = np.max(log_mel_spec)\n",
    "            if max_val > min_val:\n",
    "                log_mel_spec = (log_mel_spec - min_val) / (max_val - min_val)\n",
    "            else:\n",
    "                log_mel_spec = np.zeros_like(log_mel_spec)\n",
    "            \n",
    "            # Aggiungi dimensione batch e canale\n",
    "            log_mel_spec = np.expand_dims(np.expand_dims(log_mel_spec, axis=0), axis=0)\n",
    "            \n",
    "            # Converti in tensor\n",
    "            input_tensor = torch.tensor(log_mel_spec, dtype=torch.float32).to(device)\n",
    "            \n",
    "            # Effettua predizione\n",
    "            with torch.no_grad():\n",
    "                output = model(input_tensor)\n",
    "                scores = torch.sigmoid(output).cpu().numpy()[0]\n",
    "            \n",
    "            # Aggiungi riga al DataFrame di predizioni\n",
    "            new_row = pd.DataFrame([[row_id] + list(scores)], columns=['row_id'] + all_species)\n",
    "            predictions = pd.concat([predictions, new_row], axis=0, ignore_index=True)\n",
    "    \n",
    "    # Salva la submission come CSV\n",
    "    predictions.to_csv(\"submission.csv\", index=False)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Genera submission\n",
    "if config.environment == 'kaggle':\n",
    "    print(\"\\nGenerazione del file di submission con il nuovo metodo...\")\n",
    "    submission_df = generate_submission_simple(model)\n",
    "    \n",
    "    if submission_df is not None:\n",
    "        print(\"\\nAnteprima del file di submission:\")\n",
    "        print(submission_df.head())\n",
    "else:\n",
    "    print(\"\\nSalto la generazione della submission perché non siamo su Kaggle.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
